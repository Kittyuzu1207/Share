# Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding 一个向量就够了吗？网络嵌入中的节点多义性探讨
## Abstract  
网络嵌入模型是将网络中的节点映射成连续向量空间表示的有力工具，以便于后续的分类和链路预测等任务。现有的网络嵌入模型将每个节点的所有信息，如链接和属性，综合集成到一个嵌入向量中，以表示节点在网络中的一般角色。然而，一个现实世界的实体可能是多方面的，它由于不同的动机或自我特征而连接到不同的社区，而这些动机或自我特征并不一定相关。例如，在电影推荐系统中，用户可以同时喜爱喜剧片或恐怖片，但这两种类型的电影在嵌入空间中不太可能相互接近，用户嵌入向量也不可能同时足够接近它们。本文针对语言建模中的多义现象，提出了一种基于多义词嵌入的节点多方面建模方法。节点的每一个方面都映射到一个嵌入向量，同时在每一对节点和方面之间保持一个关联度。该方法对现有的各种嵌入模型具有自适应性，且不会使优化过程复杂化。我们还讨论了如何利用不同方面的嵌入向量进行分类和链接预测等推理任务。在真实数据集上的实验有助于综合评价该方法的性能。  

## 1 INTRO
网络是用于信息系统建模的普遍存在的数据结构，如社会网络、推荐系统、生物网络和知识图。在这些系统中，用户、项目、分子和知识概念等现实世界实体被抽象为网络中的节点，而实体之间的关系则被建模为它们之间的链接。网络嵌入的最新进展建议，通过考虑节点的neighborhood和特征信息feature info，将每个节点表示为低维向量。在嵌入空间中，相似的节点被紧密地映射在一起。节点嵌入已经被证明是一种有效的表示方案，有助于下游网络分析任务，如分类、聚类和链路预测。  
在许多实际应用中，实体可能具有不同的特征或方面。换句话说，网络中的节点可以被视为包含不同方面的capsule。事实上，从一个实体延伸到它们的邻居的不同链接可能是由其不同方面的表现造成的。在某些场景中，将这些不同的方面融合到节点的单个向量空间表示中可能会有问题。例如，在图1中客户和项目是节点的在线购物网站中，客户可能购买了不同类型的项目iitems。如果我们只用一个向量来表示每个客户，那么客户和项目的嵌入向量必须同时彼此接近。这可能很难实现，因为其他客户有不同的兴趣，这可能会扰乱嵌入向量的分布。  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/0426pic1.png)  
通过类比自然语言中单词所具有的相似性质（例如，“bank”可以指金融机构或河流附近的土地，具体取决于不同的上下文）本文将这种现象称为节点多义现象，即每个节点可以有多个方面。在此设置中，每个节点都有多个方面，而节点的每个方面都拥有嵌入向量。在这项工作中，我们希望开发一个多义网络嵌入方法，以发现节点的多个方面，并学习它们的表示。  
### Challenges
开发多义网络嵌入模型的挑战有三个方面。
- 首先是如何确定节点的facet，以及灵活地更新向量空间中不同facet的嵌入。对于每个数据样本（例如，链接links或随机游走random walk），我们需要确定每个节点的哪个方面可能被激活，以便在训练过程中更新该方面的相应嵌入。
- 第二个挑战是如何保持不同方面的嵌入向量之间的相关性。尽管我们将一个节点分成多个面，但不同的面可能并不完全相互不相关。如果我们简单地对每个方面分别建模，一些信息将丢失。
- 第三，在考虑节点多义性的情况下，如何使建模过程适应Deepwalk、LINE、PTE和GCN等已有的基础模型。此外，当考虑节点的不同侧面时，新模型的计算复杂度必然增加。因此，还需要一种有效的优化算法，特别是考虑到它与负采样的兼容性。  
具体来说，本文提出了一种多义网络嵌入方法，以考虑网络数据中节点的多个方面。节点的每个方面都使用嵌入向量表示。我们的方法可以保留不同节点面之间的相关性。所开发的建模策略灵活地应用于各种基础嵌入模型，而不必对其基础公式进行根本更改。我们首先展示如何修改Deepwalk来解决节点多义问题，然后将我们的讨论扩展到更多的基础嵌入模型和更复杂的应用场景。为了保证算法的有效性和实现的可行性，特别是在采用负采样的情况下，对多义嵌入模型的训练过程进行了优化设计。最后，为了评估考虑多个方面的节点是否有利于学习节点表示和下游数据挖掘任务，我们对不同任务进行了实验，比较了多义嵌入模型和相应的单向量基模型的性能。  
### Contributions
- 提出了一种新的多义网络嵌入方法，将节点的不同方面融入到表示学习中。节点的每个方面都有一个嵌入向量，并考虑了不同方面的嵌入向量之间的关系。  
- 我们将问题具体化，以使所得到的优化算法能够有效且可行地实现。该方法对现有的各种反导(transductive)嵌入模型具有很好的适应性。
- 我们针对不同的下游任务和应用场景进行了深入的实验，提供了如何以及何时从网络嵌入中的节点多义性建模中获益的见解。

## 2 POLYSEMOUS NETWORK EMBEDDING
本部分以Deepwalk为基础模型，介绍了多义网络嵌入的核心思想。然后，我们设计了一个优化算法来训练多义词嵌入模型。我们还将讨论如何在不同的上下文中估计节点的方面。最后，我们介绍如何将不同方面的嵌入向量组合到下游任务中，例如分类和链接预测。
### 2.1 Polysemous Deepwalk
在多义嵌入polysemous embedding的设定中，每个节点v_i和一个target embedding matrix U_i (K_i×D) 和一个context embedding matrix H_i(K_i×D)相联系。K_i是节点v_i拥有的embedding vectors的数量，考虑到其不同的facets。传统的DeepWalk model中K_i=1。D是embedding的维度，节点v_i的第k个facet的embedding vector 表示为 {U_i}^k 或{H_i}^k。不同的节点可以与不同数量的嵌入向量相关联，这取决于它们在网络中的特性的多样性。在这项工作中，为了举例说明，我们简单地让所有节点具有相同数量的嵌入向量，这样K i=K和K是一个预定义的常量整数。实际上，K的值可以由数据来估计。例如，K可以近似地设置为推荐系统中潜在兴趣类别的数目，也可以估计为学术网络中主要主题的数目。我们将在后面的部分讨论如何将facet分配给具有不同概率的节点。  
***
DeepWalk 使用了Skip-gram 模型,该模型使用最大似然估计进行训练，在此我们试图找到使获得的观测值的似然最大化的模型参数。具体来说，设θ为待优化参数，O为所有观测值的集合，待最大化的目标函数为：  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04262.png)   
其中每个observation o属于O，是一个tuple，o=(N(v_i),v_i)，由一个central node v_i 和其context组成，在这个context里的node表示为v_j,所以v_j 属于 N(v_i).model parameters e.g. the embedding vectors of nodes 被用来计算概率p(v_j|v_i),这个条件概率是给定v_i的条件下v_j出现在其context里的概率  
但是，在我们的设置中，每个节点拥有多个facets，activated facets of a node在不同的上下文中有所不同。此外，给定上下文的facet由上下文中节点的所有facets的组合确定。假设节点facets的分布是预先知道的，我们把它们当作表示为P的先验知识。考虑到其他信息，目标重新表述为：  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04263.png)  
其中s(o)表示o中所有节点activated facets的一个case，所以s(o)={s(v|o) |v ∈ v i ∪ N(v i )} 其中s（v | o）是o上下文中节点v的activated facets。在给定的观测值o中，假设v_i的activated facet是k_i，且每个v_j∈N(v_i)的activated facet是k_j，则条件概率p（o|s(o),p,θ）定义为：  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04265.png)   
其中每一个product vector按上图计算，类似于传统的skip-gram模型中的softmax归一化，只是原本的node embedding变成了 node facet embeddings。这里的<,>表示两个向量的内积。分母作为一种归一化over all possible nodes and facets。为了可读性，省略上面公式中的P，之后不会用了。  
***
由于对数函数中存在求和项，直接应用梯度下降法优化方程2∼方程4中的目标函数比较麻烦。此外，如何结合负采样[22]来近似归一化项以提高计算效率也变得不清楚。因此，我们进一步推导出目标函数如下  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04266.png)   
这种转换背后的直觉是， instead of maximizing the original objective function, we turn to maximize its lower bound 使用Jesen函数使其下界最大化。表示为上面这个亚子。除了s(o)的外求和external summation over s(o)之外，目标函数与skip gram model的类似，因此也可以采用与传统skip gram模型相同的负采样策略来近似p（vj|vi,s(o)）中的归一化项。因此，所提出的多义点嵌入模型的一个主要优点是，通过对现有学习框架的最小修改，通过增加一个额外的采样步骤 of assigning activated facets to nodes in each observation o，可以很容易地实现训练过程。  
具体而言，给定p(s(o)|P)的分布，对(s(o))的求和项是通过facet sampling separatelyfor each node in o 来实现的。算法1中给了总体优化算法。  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04267.png)   
在初始化和节点面分布估计node-facet distribution estimation（稍后将介绍）之后，像在传统的Deepwalk（第3行）中一样，对一些随机游动进行采样。然后，对于每个观测o，在o（第7行中的循环）内的每个节点上进行多轮刻面采样several rounds of facet sampling are conducted on each node within o。在每一轮中，每个node都激活了一个facet（第8∼10行），这样对应于该facet的嵌入向量将使用SGD进行更新（第11行）。与传统的Deepwalk相比，主要的额外计算成本来自于O中的训练数据增加了采样率R的一个因子**R**。  
多义Deepwalk的整个过程如图2所示，其中如上所述引入了“目标优化”，而有关方面分布和方面分配的其他步骤将在下一小节中详细讨论。  
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04264.png)   

### 2.2 Node-Facet Assignment 结点-方面分配
现在我们将介绍如何获得先验知识P，以及如何在给定特定观测o的情况下确定节点的facet。目前，我们将讨论限制在无向齐次平面网络undirected homogeneous plain networks，并提供了一种仅利用网络邻接矩阵来获得节点面全局分布的方法，对于具有属性信息的网络或异构信息网络，我们可以采用其他策略，并将其留给以后的工作。设A为网络的对称邻接矩阵，在网络上进行社区发现[15][36]：
![img](https://github.com/Kittyuzu1207/Share/blob/master/img/04268.png)   
其中 **P** 可以用梯度搜索算法，概率p(k|v)即结点v分配了第k个facet的概率，可以通过公式xxx计算。计算一个node的 facet distribution，as p(v) = [ p( 1 |v),...,p(K|v) ]。我们把p(v_i)，1≤i≤N作为先验知识p，因为它编码了对网络状态的全局理解。应用属性信息可以得到更好的估计，但超过了本文的讨论范围。   
***
在给定先验知识P后，我们能够估计出overall facet of each observation o as well as the facet of nodes within o。给定观测值o=（N（vi），vi），一个直接的方式是通过对the facet distributions of nodes inside the observation取平均，来获得its facet distribution p(o) 。即公式xxx。考虑到节点的activated facet依赖于观察到它的特定上下文，给定o，节点的facet s(v|o)根据分布p(v|o)进行采样，该分布p（v|o）的启发式定义如下:公式xxx。其中，我们引入min（·，·）运算符，因为如果p（k|vi）≈0，则不希望使用facet k分配节点vi，即使p(o)中的第k个条目很大。为了使其成为有效的概率分布，p（v|o）进一步规范化为和为1。   
到目前为止，我们已经介绍了多义词Deepwalk的整个训练过程，如图2所示。在给定输入网络的情况下，我们首先将节点刻面分布估计为先验知识P。然后，执行随机游动来构造节点上下文观测。之后，在每个walk示例o中，为每个节点分配一个激活的facet。最后，通过优化更新相应面的节点嵌入。  

### 2.3 Joint Engagement of Multiple Embeddings for Inference
在训练多义模型后，我们可以得到每个节点的多个嵌入向量。接下来的问题是，在推理过程中，如何为后续任务共同考虑不同的嵌入向量。这里我们讨论两个主要的网络分析任务，包括分类和链路预测。  
对于分类任务，对于每个node，我们的策略是combine multiple vectors into a joint vector。有一些options 比如：直接concat，或者first scale each embedding vector with the probability of belonging to the corresponding facet再concat。连接后的resultant embeddin可以直接用于node classification。我们采用的是先scale再concat。   
对于链路预测或网络重建任务，两个节点表示之间的相似度得分越高，表明节点之间存在链路的可能性越大，可以将两个节点之间的相似度定义为：公式10。其中嵌入向量的不同facet对有助于整体相似性计算，由节点属于相应方面的概率加权。  

### 2.4 Discussion
由于不同的表征维度对数据背后的不同因素敏感，因此本文的工作可能与分离表征学习相关[9]。此外，它有助于提高表示学习的可解释性[3]，因为表示维度是根据可能与实际网络对象的具体含义或特征相关联的节点方面来分离的。  

## 3 MODELS EXTENDED BY POLYSEMOUS EMBEDDING
多义信息嵌入方法也可以推广到其他基本的单嵌入模型。在本节中，我们将以两个场景为例进行阐述。首先，我们展示了如何在不同类型节点之间存在链接的异构网络中使用多义点嵌入。其次，我们展示了如何将多义信息嵌入与图神经网络相结合，用前馈模块代替Deepwalk中的嵌入查找表。

### 3.1 Polysemous PTE for Heterogeneous Networks
我们展示了在建模异构网络时如何考虑节点多义性。我们选择PTE[30]作为扩展的基础模型，因为它是解决问题的基本模型。为了简化说明，在模型开发过程中，我们只考虑二部网络。由于PTE的目标函数可以扩展为考虑多个二部或齐次网络的多个项之和，因此该讨论可以应用于更复杂的网络。  
给定一个包含两类节点V a和V B以及一组表示为E的链路的网络，每个观测o被定义为一个链路o=（u j，V i）∈E，其中vi∈va，uj∈vb。因此，所有观测值的集合被定义为O=E。与第2.1节中的推导类似，目标函数的公式如下：公式11、12  
#### 3.1.1 Node Facet Assignment
同样类似于前面一节， Given the asymmetric adjacency matrix A, we first solve:公式13。合成因子矩阵P包含V_A和facets之间的关联强度，而Q包含V_B中节点的facet关联信息。然后，我们对P和Q进行normalize，得到每个节点v_i∈v_A和u_j∈v_B的属于不同facet的概率[36]。如果我们分别用p（v_i）和p（u_j）表示这两种类型节点的面分布，则观测（即边）的面分布计算为p（o）=p（v_i）+p（u_j）/2。与多义Deepwalk不同，这里我们简单地将p（v | o）=p（o）应用于节点面采样，因为PTE中的窗口大小等于1，比Deepwalk小得多。  
#### 3.1.2 EngageMultipleEmbeddingsforInference  
对于下游任务，联合考虑节点的多个嵌入向量的方法类似于第2.3节中介绍的方法。唯一的区别是，两种不同类型节点之间的相似性度量调整为公式14.

### 3.2 Polysemous Embedding with GCN
多义信息嵌入的思想可以通过其他体系结构的模型来实现。在本小节中，我们以GCN[14]为例，说明如何将其扩展为PolyGCN来考虑节点多义。与polydepwalk和PolyPTE不停地嵌入查找表来存储嵌入向量不同，PolyGCN使用一个前馈网络模块，通过从邻居收集信息来生成每个节点的嵌入。  
在GCN中嵌入生成的核心步骤是从节点的局部邻域中聚集信息。如果u_d(i)表示节点v_i在第d层的中间表示，则正向传播为:公式15.  
其中，W_d是d层上的权重矩阵，MEAN是指预处理djacencymatrix上的聚集体，N（v_i）是v_i的局部邻域。v_i的最终嵌入输出定义为U_i=U_d_max（i），其中d max表示最终层的深度。在前向传播之后，GCN可以类似于Deepwalk或PTE的无监督方式进行训练。  
我们提出了一种可行的方法，将节点多义合并到基于GCN的模型中，其中嵌入的每个facet对应于一个GCN模型，而每个GCN的内部结构保持不变。具体地说，在某个方面k中，我们将节点的局部邻域限制为激活了相同facet k的其他节点，so that 公式16.
其中，N_k（v_i）表示facet k下的局部邻域。v_i的facet k最终嵌入输出是U^k_i=U^k_d_max（i），主要问题是如何构造节点v的特定k的局部邻域。这里我们仍然将二分网络视为场景，因此对于每个方面，有两个gcn分别用于为每种类型的节点生成嵌入。按照第3.1节中的类似策略，将观察到的链接分解为不同方面对的交互结果。我们进一步放松了这个问题，使得不同方面的嵌入是相互独立的。具体地说,原始的观测矩阵A=对k求和A^k，其中A^k>=0且A^k(i,j)与P(i,k) · Q(j,k)成比例。v_j ∈ N_k (v_i ) if both v_i and v_j connect to the same node of the other type under facet k . 对于每个GCN对的训练，我们采用了类似于文献[6]中提出的无监督训练策略，如果节点按照相应的观察矩阵连接，则encourage节点具有相似的facet k嵌入。  

## 4 EXPERIMENTS
我们试图通过实验回答几个问题。首先，与单向量嵌入方法相比，提出的多义点嵌入方法的效果如何？第二，当评估不同的下游任务时，考虑节点多义是否有利于网络嵌入？第三，多义嵌入模型如何应对超参数的变化？
### 4.1 Experimental Settings
我们首先介绍应用数据集如下。详细信息见表1。
•BlogCatalog：基于在线博主之间的联系构建的社交网络数据集。原始数据集包含链接和属性信息，而我们只保留实验中的链接。每个节点还与一个标签相关联，该标签由blogger的一些预定义兴趣类别确定。
•Flickr：一个网络数据集，由多媒体托管网站上用户之间的交互构成。每个链接对应于用户之间的以下关系。用户加入的组被视为标签。
•MovieLens：广泛用于评估协作过滤模型的电影分级数据集。在我们的实验中，我们将其视为一个异构网络，用户和项目（即电影）之间存在链接。我们将评分转换成隐式数据，这样每个条目要么是0，要么是1，指示用户是否对电影进行了评分[8]。这样，对该数据集进行推荐也可以被视为执行链路预测。
•Pinterest：最初为图像推荐而构建的隐式反馈数据。用户和图像被视为节点。每个链接都是用户发起的图像上的一个pin。每个用户至少有20个链接。类似地，链接预测任务可以被视为向用户推荐图像。  
BlogCatalog和Flickr中的网络是同质的，我们将它们用于分类和链接预测。MovieLens和Pinterest中的网络是异构的，我们将把它们应用到链路预测任务中，也可以看作是做推荐。比较的基线方法如下。  
•Deepwalk[26]、PTE[30]、GCN[38]：一些常用的网络嵌入模型，将每个节点映射到单个向量。我们将它们作为基线方法来分析它们的多义嵌入对等体是否获得更好的性能。这里的GCN只适用于异构链路预测。
•NMF[15，16]：从数据中学习潜在因素的传统模型。我们将NMF作为基线方法之一，因为我们将其应用于估计数据中包含的全局方面。在所提出的多义模型中，潜在因子的数目与面的数目相同。
•MSSG[23]：为自然语言处理开发的多意义单词嵌入模型。词的意义由其平均上下文表示的聚类决定。每个词作为上下文时只有一个嵌入向量。该模型适用于网络分析任务。
•MNE[37]：将网络邻近矩阵分解为若干组嵌入矩阵，并添加多样性约束以强制不同矩阵关注节点的不同方面的模型。由于本文没有讨论如何进行链路预测，所以我们只使用MNE进行节点分类。  

### 4.2 Node Classification
节点分类是评价网络嵌入结果的常用任务。在这个实验中，我们比较了所提出的多义词模型与基线模型的表现。我们使用Deepwalk作为基本的单嵌入模型。该模型称为polydepwalk。实验中使用了BlogCatalog和Flickr数据集。  
除非在每个任务中特别说明，否则默认模型超参数设置如下。对于BlogCatalog数据集，每个节点生成的遍历数为110，遍历长度为11，上下文大小为8，PolyDeepwalk考虑的面数为6，Deepwalk中每个节点嵌入的维度为210，PolyDeepwalk中每个节点的面数为210/6=35，Deepwalk为5，PolyDeepwalk为10对于Polydepwalk。对于Flickr数据集，参数设置是相似的，除了polydepwalk的facet s数量是5，Deepwalk中每个节点的嵌入维度是180，polydepwalk中每个节点的facet的嵌入维度是180/5=36，polydepwalk的负样本数量是15。值得注意的是，多义嵌入的维数除以面的个数，这样在连接之后，得到的嵌入长度与单个嵌入对应的长度相同。我们使用支持向量机作为分类模型，其中80%的数据样本被用作训练数据。性能比较如图3和图4所示。请注意，由于NMF的F1分数远低于其他模型，因此我们不绘制其性能图。在使用NMF相关模型进行节点分类时，一些工作包括将节点属性作为附加信息源[11，17]，但这超出了我们的实验设置。从这些图中，一些观察总结如下:  
•一般来说，polydepwalk比其他的多义嵌入模型具有更好的性能。此外，通过改变维数，我们可以观察到多义嵌入模型受影响的可能性较小，而Deepwalk的分类性能随着维数的增加而逐渐降低。
•Deepwalk和polydepwalk对上下文大小的变化有不同的响应。前者随着上下文大小的增加而获得更好的性能，而后者则呈现相反的趋势。一个可能的原因是，随着polydepwalk中上下文窗口的放大，来自每个节点的随机行走更可能到达不同方面的其他网络区域。结果，方面分布被过度平滑，因此更难确定上下文窗口属于哪个方面。这可能是今后工作中要解决的挑战之一。
除与基线模型进行比较外，还分析了节点多义建模时polydepwalk对一些关键参数的敏感性。实验结果如图5所示。一些意见如下：  
•增加面数对拟议模型的分类性能有积极影响。值得注意的是，我们保留了总嵌入维数（即K×D polydepwalk）的定义，其中D polydepwalk实际上随着K的增加而增加，这样下游分类任务就不会受到特征大小的影响
•在实验的这一部分中，改变每次观察的小面采样率（即上下文窗口）不会显著影响结果。可能的原因是每个节点都生成了许多随机游动，因此也隐式地对每个随机游动执行面采样。即使我们降低了每个上下文窗口的方面采样率，训练样本也已经足够了。

### 4.3 Link Prediction in Homogeneous Networks



